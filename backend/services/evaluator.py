# backend/services/evaluator.py

from typing import Dict, Any, List
from services.ollama_llm import ollama_generate


class RAGEvaluator:
    """
    Evaluator fully powered by local Ollama — no Grok/Gemini anymore.
    """

    def __init__(self, model_name: str = None):
        self.model_name = model_name

    def evaluate_response(
        self,
        query: str,
        generated_answer: str,
        expected_answer: str = None,
        context_chunks: List[str] = None
    ) -> Dict[str, Any]:

        context_section = ""
        if context_chunks:
            context_section = "\n".join([f"[{i+1}] {c}" for i, c in enumerate(context_chunks)])

        expected_section = f"\nEXPECTED ANSWER:\n{expected_answer}\n" if expected_answer else ""

        prompt = f"""
You are a strict evaluator for a RAG system.
Score the generated answer on a scale of 0–100 for:

1. Relevance  
2. Accuracy  
3. Completeness  
4. Coherence  
5. Faithfulness  

Return ONLY scores in JSON:

{{
  "relevance": ...,
  "accuracy": ...,
  "completeness": ...,
  "coherence": ...,
  "faithfulness": ...,
  "overall": ...
}}

QUERY:
{query}

GENERATED ANSWER:
{generated_answer}

{expected_section}

CONTEXT:
{context_section}
"""

        try:
            text = ollama_generate(prompt, model=self.model_name or "llama3.1")

            import json
            scores = json.loads(text)

            return {
                "scores": scores,
                "feedback": "Evaluation generated by Ollama.",
                "evaluator_model": self.model_name or "llama3.1"
            }

        except Exception as e:
            # fallback
            return {
                "scores": {
                    "relevance": 50,
                    "accuracy": 50,
                    "completeness": 50,
                    "coherence": 50,
                    "faithfulness": 50,
                    "overall": 50
                },
                "feedback": "[Fallback evaluator]",
                "error": str(e)
            }


# singleton
_evaluator = None

def get_evaluator(model_name: str = None) -> RAGEvaluator:
    global _evaluator
    if _evaluator is None:
        _evaluator = RAGEvaluator(model_name)
    return _evaluator
